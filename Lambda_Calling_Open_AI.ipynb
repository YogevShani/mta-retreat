{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Lambda Function Calling Open AI**\n"
      ],
      "metadata": {
        "id": "xS-56g4QVU8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78stJabtVNVG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "\n",
        "    key = \"OPEN-AI-KEY\"\n",
        "\n",
        "    client = OpenAI(\n",
        "        api_key=key)\n",
        "\n",
        "    conversation_history = event.get(\"conversation_history\", [])\n",
        "    #user_prompt = event['queryStringParameters']['user_prompt']\n",
        "    user_prompt = event.get('queryStringParameters', {}).get('user_prompt')\n",
        "\n",
        "    print(event)\n",
        "    print(user_prompt)\n",
        "\n",
        "    if not user_prompt:\n",
        "        return {\"statusCode\": 400, \"body\": json.dumps({\"error\": \"user_prompt is required\"})}\n",
        "\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=conversation_history,\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        max_tokens=100\n",
        "    )\n",
        "\n",
        "    ai_reply = chat_completion.choices[0].message.content\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
        "\n",
        "    return {\n",
        "        \"statusCode\": 200,\n",
        "        \"body\": json.dumps({\"ai_reply\": ai_reply})\n",
        "        # \"conversation_history\": conversation_history\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Test Lambda Function**\n",
        "We can test the function before we upload it to AWS"
      ],
      "metadata": {
        "id": "OLeENDYKWgcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function to call the Lambda\n",
        "def test_lambda():\n",
        "    event = {\n",
        "        \"queryStringParameters\": {\n",
        "            \"user_prompt\": \"1+1=?\"\n",
        "        }\n",
        "    }\n",
        "    context = {}\n",
        "\n",
        "    response = lambda_handler(event, context)\n",
        "    result = json.loads(response['body'])\n",
        "    print(\"AI Reply:\", result['ai_reply'])\n",
        "\n",
        "# Run the test\n",
        "test_lambda()"
      ],
      "metadata": {
        "id": "UBccEmdjWn41"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}